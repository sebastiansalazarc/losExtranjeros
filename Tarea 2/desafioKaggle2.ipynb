{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H88XB_WR9ID",
        "outputId": "4fc5aeb8-d4c8-4751-c2ea-3023f2e1c2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/612.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m604.2/612.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTpgA9LmT-Bb",
        "outputId": "f194fd4e-597c-4eb1-8243-69eb02895feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhAWp9XySCZl",
        "outputId": "dcf9c12a-d0b5-420d-a280-98ede814f657"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRX4spGKUYa0"
      },
      "source": [
        "#### Insert here my x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI6yFkuEUX-D"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(path_images, target_tuple, image_size, show_images):\n",
        "    # Recover image_paths\n",
        "    image_paths = [f for f in os.listdir(path_images) if os.path.isfile(os.path.join(path_images, f))]\n",
        "\n",
        "    # iteramos sobre las imagenes\n",
        "    imageRange = 100 # maximo len(image_paths)\n",
        "    #print(imageRange)\n",
        "\n",
        "    images, targets = [], []\n",
        "\n",
        "    for i in range(0, imageRange): # i = 0, 1, ... , 750 (source full training independent of secret test)\n",
        "\n",
        "        #print(path_images)\n",
        "\n",
        "        # cargamos la imagen\n",
        "        image = keras.utils.load_img(path_images + \"/\" + image_paths[i]) # <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=427x207 at 0x7CD26E127370>\n",
        "\n",
        "        # obtenemos el tamaño de la imagen\n",
        "        #(w, h) = image.size[:2]\n",
        "\n",
        "        # reescalamos la imagen\n",
        "        image = image.resize((image_size, image_size))\n",
        "\n",
        "        # convertimos la imagen a un array y la almacenamos en la lista\n",
        "        to_array = keras.utils.img_to_array(image)\n",
        "        # to_array = to_array/255. # normalization of array not done in keras.io\n",
        "        images.append(to_array)\n",
        "\n",
        "        # Agregamos targets normalizados a la lista\n",
        "        targets.append(target_tuple)\n",
        "\n",
        "        # Switch para visualizar imagenes en el run\n",
        "        if show_images == 1:\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')  # Turn off axis labels and ticks\n",
        "            plt.show()\n",
        "\n",
        "    return images, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiEozHSQUlga"
      },
      "outputs": [],
      "source": [
        "# Load dish dictionary with 101 dishes\n",
        "dish_dict = {\n",
        "    \"0\": \"foie_gras\",\n",
        "    \"1\": \"club_sandwich\",\n",
        "    \"2\": \"cheese_plate\",\n",
        "    \"3\": \"cup_cakes\",\n",
        "    \"4\": \"garlic_bread\",\n",
        "    \"5\": \"gnocchi\",\n",
        "    \"6\": \"ice_cream\",\n",
        "    \"7\": \"samosa\",\n",
        "    \"8\": \"donuts\",\n",
        "    \"9\": \"tuna_tartare\",\n",
        "    \"10\": \"filet_mignon\",\n",
        "    \"11\": \"seaweed_salad\",\n",
        "    \"12\": \"french_toast\",\n",
        "    \"13\": \"chicken_curry\",\n",
        "    \"14\": \"shrimp_and_grits\",\n",
        "    \"15\": \"steak\",\n",
        "    \"16\": \"cheesecake\",\n",
        "    \"17\": \"red_velvet_cake\",\n",
        "    \"18\": \"waffles\",\n",
        "    \"19\": \"churros\",\n",
        "    \"20\": \"gyoza\",\n",
        "    \"21\": \"lobster_roll_sandwich\",\n",
        "    \"22\": \"huevos_rancheros\",\n",
        "    \"23\": \"breakfast_burrito\",\n",
        "    \"24\": \"grilled_cheese_sandwich\",\n",
        "    \"25\": \"spaghetti_bolognese\",\n",
        "    \"26\": \"falafel\",\n",
        "    \"27\": \"poutine\",\n",
        "    \"28\": \"greek_salad\",\n",
        "    \"29\": \"beef_tartare\",\n",
        "    \"30\": \"fried_calamari\",\n",
        "    \"31\": \"guacamole\",\n",
        "    \"32\": \"ravioli\",\n",
        "    \"33\": \"lobster_bisque\",\n",
        "    \"34\": \"beet_salad\",\n",
        "    \"35\": \"risotto\",\n",
        "    \"36\": \"crab_cakes\",\n",
        "    \"37\": \"strawberry_shortcake\",\n",
        "    \"38\": \"edamame\",\n",
        "    \"39\": \"ceviche\",\n",
        "    \"40\": \"hot_and_sour_soup\",\n",
        "    \"41\": \"spring_rolls\",\n",
        "    \"42\": \"sashimi\",\n",
        "    \"43\": \"paella\",\n",
        "    \"44\": \"clam_chowder\",\n",
        "    \"45\": \"miso_soup\",\n",
        "    \"46\": \"escargots\",\n",
        "    \"47\": \"hot_dog\",\n",
        "    \"48\": \"pulled_pork_sandwich\",\n",
        "    \"49\": \"bruschetta\",\n",
        "    \"50\": \"panna_cotta\",\n",
        "    \"51\": \"fish_and_chips\",\n",
        "    \"52\": \"pad_thai\",\n",
        "    \"53\": \"tiramisu\",\n",
        "    \"54\": \"takoyaki\",\n",
        "    \"55\": \"macarons\",\n",
        "    \"56\": \"apple_pie\",\n",
        "    \"57\": \"cannoli\",\n",
        "    \"58\": \"scallops\",\n",
        "    \"59\": \"frozen_yogurt\",\n",
        "    \"60\": \"chicken_quesadilla\",\n",
        "    \"61\": \"mussels\",\n",
        "    \"62\": \"beef_carpaccio\",\n",
        "    \"63\": \"eggs_benedict\",\n",
        "    \"64\": \"spaghetti_carbonara\",\n",
        "    \"65\": \"omelette\",\n",
        "    \"66\": \"sushi\",\n",
        "    \"67\": \"chocolate_mousse\",\n",
        "    \"68\": \"beignets\",\n",
        "    \"69\": \"bibimbap\",\n",
        "    \"70\": \"hummus\",\n",
        "    \"71\": \"pork_chop\",\n",
        "    \"72\": \"chicken_wings\",\n",
        "    \"73\": \"grilled_salmon\",\n",
        "    \"74\": \"chocolate_cake\",\n",
        "    \"75\": \"tacos\",\n",
        "    \"76\": \"hamburger\",\n",
        "    \"77\": \"baby_back_ribs\",\n",
        "    \"78\": \"pancakes\",\n",
        "    \"79\": \"prime_rib\",\n",
        "    \"80\": \"pizza\",\n",
        "    \"81\": \"nachos\",\n",
        "    \"82\": \"macaroni_and_cheese\",\n",
        "    \"83\": \"bread_pudding\",\n",
        "    \"84\": \"ramen\",\n",
        "    \"85\": \"croque_madame\",\n",
        "    \"86\": \"lasagna\",\n",
        "    \"87\": \"peking_duck\",\n",
        "    \"88\": \"deviled_eggs\",\n",
        "    \"89\": \"french_fries\",\n",
        "    \"90\": \"dumplings\",\n",
        "    \"91\": \"fried_rice\",\n",
        "    \"92\": \"french_onion_soup\",\n",
        "    \"93\": \"pho\",\n",
        "    \"94\": \"caprese_salad\",\n",
        "    \"95\": \"oysters\",\n",
        "    \"96\": \"baklava\",\n",
        "    \"97\": \"creme_brulee\",\n",
        "    \"98\": \"carrot_cake\",\n",
        "    \"99\": \"onion_rings\",\n",
        "    \"100\": \"caesar_salad\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZUtkjwgUpcG"
      },
      "outputs": [],
      "source": [
        "# Define function to get key by value in a dictionary\n",
        "def getKeyByValue(dictionary, value):\n",
        "    for key, val in dictionary.items():\n",
        "        if val == value:\n",
        "            return key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvfiVaeUUrbi"
      },
      "outputs": [],
      "source": [
        "# Define function to get main key by value of inner dictionary\n",
        "def findOuterKey(data, value_to_find):\n",
        "    for outer_key, inner_dict in data.items():\n",
        "        for inner_key, inner_value in inner_dict.items():\n",
        "            if inner_value == value_to_find:\n",
        "                return outer_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3RIxcPQGU9YK",
        "outputId": "d4ec31fe-d6c3-4ae6-b737-f47b4462a07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 32, 32, 3)\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "# Recorrer carpetas de training\n",
        "#source_folder = \"/content/drive/MyDrive/Colab Notebooks/kaggle_tarea2/images_train/\"\n",
        "#source_folder = \"/content/drive/MyDrive/kaggle_tarea2/images_train/\"\n",
        "source_folder = \"/content/drive/MyDrive/Colab Notebooks/INF-395/Tarea-2/kaggle_tarea2/images_train/\"\n",
        "\n",
        "# Initialize full lists\n",
        "images, targets = [], []\n",
        "\n",
        "for foldername_train in os.listdir(source_folder):\n",
        "\n",
        "    # foldername_train # apple_pie_train\n",
        "\n",
        "    # Extract first part of folder name\n",
        "    foldername = foldername_train.replace(\"_train\", \"\") # apple_pie\n",
        "\n",
        "    # Retain dish key in dish_dict\n",
        "    dish_dict_key = getKeyByValue(dish_dict, foldername)\n",
        "    dish_dict_key_norm = int(dish_dict_key) # normalization not done in keras.io\n",
        "\n",
        "    # Retain food categorie key in hierarchy_dict\n",
        "    #food_categorie_key_str = findOuterKey(hierarchy_dict, foldername)\n",
        "\n",
        "    # Retain food categorie Number in food_categories_dict\n",
        "    #food_categorie_key = getKeyByValue(food_categories_dict, food_categorie_key_str)\n",
        "    #food_categorie_key = int(food_categorie_key) # convert to int\n",
        "\n",
        "    # CASE 0: Multiple targets\n",
        "    # dish: dish_num / dish_num normalized / food_categorie_str / food_categorie_key\n",
        "    #print(foldername, \": \", dish_dict_key, dish_dict_key_norm, food_categorie_key_str, food_categorie_key)\n",
        "\n",
        "    # CASE 1: Simplefied (1 target)\n",
        "    # print(foldername, \": \", dish_dict_key, dish_dict_key_norm) # avoid printing for speed\n",
        "\n",
        "    # Collect training folder full path of preprocessing\n",
        "    path_images = os.path.join(source_folder, foldername_train) # /content/drive/MyDrive/Colab Notebooks/kaggle_tarea2/images_train/apple_pie_train\n",
        "\n",
        "    # Apply preprocess fun\n",
        "    image_size = 32\n",
        "    show_images = 0 # 1: show, 0: not show\n",
        "    target_tuple = dish_dict_key_norm # according to certain dish & normalized\n",
        "    images, targets = preprocess_image(path_images, target_tuple, image_size, show_images)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "targets = np.array(targets)\n",
        "\n",
        "# convertimos las listas a arrays para el conjunto final de entrenamiento y validation (80% y 20% respectivamente)\n",
        "(x_train), (y_train) = (\n",
        "        np.asarray(images[: int(len(images) * 0.8)]),\n",
        "        np.asarray(targets[: int(len(targets) * 0.8)]),\n",
        "        )\n",
        "(x_val), (y_val) = (\n",
        "        np.asarray(images[int(len(images) * 0.8) :]),\n",
        "        np.asarray(targets[int(len(targets) * 0.8) :]),\n",
        "        )\n",
        "\n",
        "# show shape results\n",
        "print(images.shape)\n",
        "print(targets.shape)\n",
        "\n",
        "# save memory\n",
        "del images\n",
        "del targets\n",
        "\n",
        "# reshape vectors\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_val = y_val.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFFoFfkTJL1I"
      },
      "source": [
        "#### Guardar tensores para no volver a procesarlos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcwMxNuAIQ2c"
      },
      "outputs": [],
      "source": [
        "# No borrar carpeta, aunque si se puede vaciar\n",
        "saving_path = \"/content/drive/MyDrive/Colab Notebooks/kaggle_tarea2/saved_tensors/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdoxxANfrN2q"
      },
      "outputs": [],
      "source": [
        "# js\n",
        "saving_path = \"/content/drive/MyDrive/kaggle_tarea2/saved_tensors/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjNPWrOmJQDj"
      },
      "outputs": [],
      "source": [
        "# No correr si ya estan guardados\n",
        "#np.save(saving_path + 'x_train.npy', x_train)\n",
        "#np.save(saving_path + 'y_train.npy', y_train)\n",
        "#np.save(saving_path + 'x_val.npy', x_val)\n",
        "#np.save(saving_path + 'y_val.npy', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYNuiUULJSAg"
      },
      "outputs": [],
      "source": [
        "# Correr solo si ya estan guardados\n",
        "x_train = np.load(saving_path + 'x_train.npy')\n",
        "y_train = np.load(saving_path + 'y_train.npy')\n",
        "x_val = np.load(saving_path + 'x_val.npy')\n",
        "y_val = np.load(saving_path + 'y_val.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTlAPLozNBc-"
      },
      "source": [
        "#### Review shapes of subtraining and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoqEuGxmM62x",
        "outputId": "b1787cc7-8a31-4ea0-b746-c4f84b20842d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60608, 32, 32, 3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx6nMiLHM8bH",
        "outputId": "edab14cf-1b0e-452a-a86b-a1ffeedf65ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60608, 1)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozk6zBL7M-PW",
        "outputId": "b4793e75-ec3a-4217-af18-f59de7716de2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15152, 32, 32, 3)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu_6M6KGM_nF",
        "outputId": "8f45f641-91f0-4354-f567-5f4422c2e9f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15152, 1)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPNu9iYfaEyT"
      },
      "source": [
        "#### Retake code of keras.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-eEYbdOSNf4",
        "outputId": "48507849-fc59-47c5-873d-0ffba5f5dc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60608, 32, 32, 3) - y_train shape: (60608, 1)\n",
            "x_val shape: (15152, 32, 32, 3) - y_val shape: (15152, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 101\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape} - y_val shape: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUpdiFXvSPZt",
        "outputId": "dd19747d-0c3c-4b0d-9f1a-234adf551e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[ 89.,  19.,  15.],\n",
              "         [ 87.,  22.,  19.],\n",
              "         [ 80.,  17.,  13.],\n",
              "         ...,\n",
              "         [198., 187., 155.],\n",
              "         [197., 188., 155.],\n",
              "         [196., 189., 158.]],\n",
              "\n",
              "        [[ 83.,  21.,  17.],\n",
              "         [ 79.,  21.,  16.],\n",
              "         [ 71.,  16.,   9.],\n",
              "         ...,\n",
              "         [199., 190., 158.],\n",
              "         [202., 193., 160.],\n",
              "         [201., 194., 165.]],\n",
              "\n",
              "        [[ 62.,  12.,   9.],\n",
              "         [ 63.,  14.,   7.],\n",
              "         [ 66.,  16.,   9.],\n",
              "         ...,\n",
              "         [195., 186., 154.],\n",
              "         [198., 188., 154.],\n",
              "         [199., 193., 162.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[180., 186., 173.],\n",
              "         [212., 216., 208.],\n",
              "         [215., 221., 220.],\n",
              "         ...,\n",
              "         [196., 198., 203.],\n",
              "         [198., 198., 205.],\n",
              "         [197., 201., 210.]],\n",
              "\n",
              "        [[159., 155., 139.],\n",
              "         [213., 217., 212.],\n",
              "         [216., 222., 221.],\n",
              "         ...,\n",
              "         [195., 198., 203.],\n",
              "         [198., 201., 206.],\n",
              "         [199., 202., 211.]],\n",
              "\n",
              "        [[155., 144., 130.],\n",
              "         [216., 221., 219.],\n",
              "         [217., 223., 223.],\n",
              "         ...,\n",
              "         [197., 200., 207.],\n",
              "         [201., 203., 208.],\n",
              "         [198., 202., 211.]]],\n",
              "\n",
              "\n",
              "       [[[ 96.,  78.,  47.],\n",
              "         [ 95.,  79.,  47.],\n",
              "         [ 97.,  82.,  51.],\n",
              "         ...,\n",
              "         [165., 153., 120.],\n",
              "         [161., 147., 113.],\n",
              "         [159., 140., 109.]],\n",
              "\n",
              "        [[ 81.,  64.,  39.],\n",
              "         [ 90.,  70.,  45.],\n",
              "         [ 98.,  82.,  52.],\n",
              "         ...,\n",
              "         [167., 154., 120.],\n",
              "         [161., 147., 112.],\n",
              "         [155., 138., 105.]],\n",
              "\n",
              "        [[ 73.,  58.,  32.],\n",
              "         [ 78.,  61.,  37.],\n",
              "         [ 93.,  74.,  42.],\n",
              "         ...,\n",
              "         [165., 153., 120.],\n",
              "         [157., 145., 109.],\n",
              "         [151., 135., 104.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[173., 179., 149.],\n",
              "         [178., 184., 154.],\n",
              "         [176., 182., 151.],\n",
              "         ...,\n",
              "         [168., 173., 145.],\n",
              "         [163., 169., 142.],\n",
              "         [166., 171., 147.]],\n",
              "\n",
              "        [[171., 179., 149.],\n",
              "         [176., 185., 153.],\n",
              "         [175., 181., 150.],\n",
              "         ...,\n",
              "         [166., 172., 144.],\n",
              "         [162., 168., 139.],\n",
              "         [145., 149., 121.]],\n",
              "\n",
              "        [[174., 180., 152.],\n",
              "         [173., 181., 148.],\n",
              "         [172., 179., 148.],\n",
              "         ...,\n",
              "         [165., 170., 141.],\n",
              "         [158., 164., 134.],\n",
              "         [116., 113.,  86.]]],\n",
              "\n",
              "\n",
              "       [[[228., 203., 167.],\n",
              "         [232., 208., 175.],\n",
              "         [234., 210., 179.],\n",
              "         ...,\n",
              "         [240., 225., 209.],\n",
              "         [239., 225., 210.],\n",
              "         [239., 225., 210.]],\n",
              "\n",
              "        [[230., 205., 173.],\n",
              "         [233., 210., 177.],\n",
              "         [234., 212., 179.],\n",
              "         ...,\n",
              "         [242., 229., 215.],\n",
              "         [242., 231., 218.],\n",
              "         [241., 233., 221.]],\n",
              "\n",
              "        [[230., 206., 172.],\n",
              "         [234., 211., 178.],\n",
              "         [237., 215., 177.],\n",
              "         ...,\n",
              "         [245., 235., 224.],\n",
              "         [245., 239., 230.],\n",
              "         [246., 245., 239.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[  8.,  18.,  10.],\n",
              "         [ 11.,  21.,  11.],\n",
              "         [ 13.,  22.,   9.],\n",
              "         ...,\n",
              "         [ 19.,  26.,  13.],\n",
              "         [ 12.,  22.,  11.],\n",
              "         [ 10.,  19.,  11.]],\n",
              "\n",
              "        [[ 16.,  24.,  11.],\n",
              "         [  7.,  18.,   8.],\n",
              "         [  8.,  18.,   8.],\n",
              "         ...,\n",
              "         [ 14.,  22.,  11.],\n",
              "         [ 12.,  20.,  10.],\n",
              "         [ 79.,  69.,  44.]],\n",
              "\n",
              "        [[ 94.,  72.,  41.],\n",
              "         [ 14.,  23.,  10.],\n",
              "         [  6.,  16.,   8.],\n",
              "         ...,\n",
              "         [ 11.,  20.,  10.],\n",
              "         [ 57.,  51.,  29.],\n",
              "         [198., 156., 119.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 28.,  25.,  24.],\n",
              "         [ 66.,  56.,  51.],\n",
              "         [141., 133., 124.],\n",
              "         ...,\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.]],\n",
              "\n",
              "        [[195., 169., 155.],\n",
              "         [244., 235., 219.],\n",
              "         [151., 132., 115.],\n",
              "         ...,\n",
              "         [231., 221., 221.],\n",
              "         [231., 221., 222.],\n",
              "         [236., 227., 228.]],\n",
              "\n",
              "        [[226., 210., 204.],\n",
              "         [255., 251., 239.],\n",
              "         [187., 170., 158.],\n",
              "         ...,\n",
              "         [192., 156., 147.],\n",
              "         [219., 191., 183.],\n",
              "         [232., 220., 217.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[249., 206., 187.],\n",
              "         [248., 204., 186.],\n",
              "         [233., 186., 163.],\n",
              "         ...,\n",
              "         [ 59.,  38.,  35.],\n",
              "         [142., 107., 102.],\n",
              "         [226., 178., 173.]],\n",
              "\n",
              "        [[250., 206., 183.],\n",
              "         [251., 210., 189.],\n",
              "         [249., 206., 186.],\n",
              "         ...,\n",
              "         [235., 182., 176.],\n",
              "         [254., 204., 199.],\n",
              "         [252., 205., 203.]],\n",
              "\n",
              "        [[246., 199., 172.],\n",
              "         [250., 208., 185.],\n",
              "         [251., 211., 188.],\n",
              "         ...,\n",
              "         [246., 196., 189.],\n",
              "         [249., 197., 194.],\n",
              "         [248., 199., 196.]]],\n",
              "\n",
              "\n",
              "       [[[142.,  99.,  70.],\n",
              "         [142.,  98.,  69.],\n",
              "         [141.,  96.,  67.],\n",
              "         ...,\n",
              "         [ 23.,  17.,  15.],\n",
              "         [ 20.,  15.,  13.],\n",
              "         [ 17.,  13.,  12.]],\n",
              "\n",
              "        [[145., 103.,  73.],\n",
              "         [147., 106.,  76.],\n",
              "         [144., 100.,  70.],\n",
              "         ...,\n",
              "         [115.,  70.,  49.],\n",
              "         [112.,  67.,  48.],\n",
              "         [108.,  65.,  47.]],\n",
              "\n",
              "        [[148., 108.,  78.],\n",
              "         [147., 106.,  76.],\n",
              "         [143., 101.,  72.],\n",
              "         ...,\n",
              "         [137.,  74.,  51.],\n",
              "         [140.,  88.,  60.],\n",
              "         [141.,  90.,  60.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[156.,  24.,  15.],\n",
              "         [161.,  25.,  16.],\n",
              "         [165.,  26.,  18.],\n",
              "         ...,\n",
              "         [174.,  36.,  26.],\n",
              "         [174.,  35.,  26.],\n",
              "         [167.,  36.,  30.]],\n",
              "\n",
              "        [[150.,  94.,  86.],\n",
              "         [154.,  25.,  16.],\n",
              "         [161.,  24.,  16.],\n",
              "         ...,\n",
              "         [175.,  36.,  26.],\n",
              "         [167.,  34.,  25.],\n",
              "         [158.,  29.,  23.]],\n",
              "\n",
              "        [[162., 148., 139.],\n",
              "         [155., 104.,  96.],\n",
              "         [153.,  26.,  17.],\n",
              "         ...,\n",
              "         [167.,  38.,  29.],\n",
              "         [161.,  33.,  24.],\n",
              "         [154.,  29.,  22.]]],\n",
              "\n",
              "\n",
              "       [[[215., 213., 212.],\n",
              "         [152., 143., 144.],\n",
              "         [137., 132., 134.],\n",
              "         ...,\n",
              "         [171., 149., 152.],\n",
              "         [180., 166., 168.],\n",
              "         [235., 235., 236.]],\n",
              "\n",
              "        [[149., 145., 146.],\n",
              "         [103.,  84.,  68.],\n",
              "         [ 43.,  11.,   8.],\n",
              "         ...,\n",
              "         [142.,   0.,   0.],\n",
              "         [114.,  16.,  19.],\n",
              "         [203., 204., 207.]],\n",
              "\n",
              "        [[133., 129., 130.],\n",
              "         [121.,  70.,  57.],\n",
              "         [138.,  10.,   9.],\n",
              "         ...,\n",
              "         [ 85.,   2.,   3.],\n",
              "         [ 63.,   9.,  12.],\n",
              "         [182., 182., 186.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[130., 109., 109.],\n",
              "         [121.,   0.,   0.],\n",
              "         [138.,   1.,   1.],\n",
              "         ...,\n",
              "         [148.,   5.,   2.],\n",
              "         [106.,   8.,  10.],\n",
              "         [184., 184., 188.]],\n",
              "\n",
              "        [[147., 138., 135.],\n",
              "         [ 83.,   0.,   0.],\n",
              "         [121.,   0.,   0.],\n",
              "         ...,\n",
              "         [137.,  14.,   5.],\n",
              "         [101.,  13.,  14.],\n",
              "         [199., 200., 203.]],\n",
              "\n",
              "        [[214., 213., 208.],\n",
              "         [145., 139., 136.],\n",
              "         [144., 120., 118.],\n",
              "         ...,\n",
              "         [149., 123., 123.],\n",
              "         [163., 147., 148.],\n",
              "         [235., 236., 236.]]]], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EA1BmilSSne",
        "outputId": "378adf85-bb24-4be6-9504-f6f152a628cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[56],\n",
              "       [56],\n",
              "       [56],\n",
              "       ...,\n",
              "       [79],\n",
              "       [79],\n",
              "       [79]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMHgd8z8SW6T"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 100\n",
        "image_size = 72  # We'll resize input images to this size (72 original)\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6e1enxoS0y8"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXbE9QmyS3D_"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtykoIN9S6AW"
      },
      "outputs": [],
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "qKOoKY-AS7RJ",
        "outputId": "0b65596d-ff05-43c0-abe2-c688cd57c087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCNP01ciS8uo"
      },
      "outputs": [],
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDak3p-iTNZY"
      },
      "outputs": [],
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sQKSkXZTT93",
        "outputId": "4652d0bd-329c-46b9-feb9-72195052846e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "214/214 [==============================] - 98s 380ms/step - loss: 4.3940 - accuracy: 0.0321 - top-5-accuracy: 0.1285 - val_loss: 8.5717 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "214/214 [==============================] - 82s 382ms/step - loss: 3.9988 - accuracy: 0.0656 - top-5-accuracy: 0.2191 - val_loss: 11.5410 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0012\n",
            "Epoch 3/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.8513 - accuracy: 0.0869 - top-5-accuracy: 0.2718 - val_loss: 12.2838 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 1.6499e-04\n",
            "Epoch 4/100\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 3.7361 - accuracy: 0.1077 - top-5-accuracy: 0.3122 - val_loss: 11.6962 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0026\n",
            "Epoch 5/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.6506 - accuracy: 0.1232 - top-5-accuracy: 0.3432 - val_loss: 13.8102 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0025\n",
            "Epoch 6/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.5718 - accuracy: 0.1411 - top-5-accuracy: 0.3709 - val_loss: 13.9311 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0031\n",
            "Epoch 7/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.4976 - accuracy: 0.1559 - top-5-accuracy: 0.3938 - val_loss: 13.8032 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 1.6499e-04\n",
            "Epoch 8/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.4325 - accuracy: 0.1690 - top-5-accuracy: 0.4148 - val_loss: 13.5389 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0018\n",
            "Epoch 9/100\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 3.3564 - accuracy: 0.1834 - top-5-accuracy: 0.4391 - val_loss: 14.4212 - val_accuracy: 1.6499e-04 - val_top-5-accuracy: 0.0046\n",
            "Epoch 10/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.2887 - accuracy: 0.1972 - top-5-accuracy: 0.4544 - val_loss: 13.3853 - val_accuracy: 0.0000e+00 - val_top-5-accuracy: 0.0013\n",
            "Epoch 11/100\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 3.2295 - accuracy: 0.2089 - top-5-accuracy: 0.4729 - val_loss: 14.1076 - val_accuracy: 8.2495e-04 - val_top-5-accuracy: 0.0053\n",
            "Epoch 12/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 3.1564 - accuracy: 0.2242 - top-5-accuracy: 0.4952 - val_loss: 13.7309 - val_accuracy: 8.2495e-04 - val_top-5-accuracy: 0.0078\n",
            "Epoch 13/100\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 3.0981 - accuracy: 0.2381 - top-5-accuracy: 0.5110 - val_loss: 14.5251 - val_accuracy: 0.0023 - val_top-5-accuracy: 0.0120\n",
            "Epoch 14/100\n",
            "214/214 [==============================] - 82s 385ms/step - loss: 3.0336 - accuracy: 0.2489 - top-5-accuracy: 0.5291 - val_loss: 13.6184 - val_accuracy: 0.0028 - val_top-5-accuracy: 0.0129\n",
            "Epoch 15/100\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 2.9766 - accuracy: 0.2595 - top-5-accuracy: 0.5418 - val_loss: 14.1794 - val_accuracy: 0.0049 - val_top-5-accuracy: 0.0135\n",
            "Epoch 16/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 2.9272 - accuracy: 0.2705 - top-5-accuracy: 0.5541 - val_loss: 13.5035 - val_accuracy: 0.0035 - val_top-5-accuracy: 0.0125\n",
            "Epoch 17/100\n",
            "214/214 [==============================] - 83s 386ms/step - loss: 2.8781 - accuracy: 0.2803 - top-5-accuracy: 0.5652 - val_loss: 14.3372 - val_accuracy: 0.0064 - val_top-5-accuracy: 0.0165\n",
            "Epoch 18/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.8198 - accuracy: 0.2898 - top-5-accuracy: 0.5826 - val_loss: 13.9662 - val_accuracy: 0.0046 - val_top-5-accuracy: 0.0144\n",
            "Epoch 19/100\n",
            "214/214 [==============================] - 83s 386ms/step - loss: 2.7847 - accuracy: 0.2986 - top-5-accuracy: 0.5911 - val_loss: 14.0822 - val_accuracy: 0.0078 - val_top-5-accuracy: 0.0183\n",
            "Epoch 20/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.7313 - accuracy: 0.3104 - top-5-accuracy: 0.6037 - val_loss: 13.8428 - val_accuracy: 0.0061 - val_top-5-accuracy: 0.0160\n",
            "Epoch 21/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 2.6941 - accuracy: 0.3179 - top-5-accuracy: 0.6139 - val_loss: 13.9757 - val_accuracy: 0.0036 - val_top-5-accuracy: 0.0144\n",
            "Epoch 22/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 2.6503 - accuracy: 0.3244 - top-5-accuracy: 0.6262 - val_loss: 14.3399 - val_accuracy: 0.0069 - val_top-5-accuracy: 0.0153\n",
            "Epoch 23/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.6095 - accuracy: 0.3373 - top-5-accuracy: 0.6337 - val_loss: 13.8186 - val_accuracy: 0.0053 - val_top-5-accuracy: 0.0130\n",
            "Epoch 24/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.5741 - accuracy: 0.3441 - top-5-accuracy: 0.6417 - val_loss: 14.3101 - val_accuracy: 0.0059 - val_top-5-accuracy: 0.0150\n",
            "Epoch 25/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.5381 - accuracy: 0.3514 - top-5-accuracy: 0.6507 - val_loss: 14.5393 - val_accuracy: 0.0068 - val_top-5-accuracy: 0.0165\n",
            "Epoch 26/100\n",
            "214/214 [==============================] - 80s 375ms/step - loss: 2.5050 - accuracy: 0.3557 - top-5-accuracy: 0.6598 - val_loss: 14.3057 - val_accuracy: 0.0099 - val_top-5-accuracy: 0.0188\n",
            "Epoch 27/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.4643 - accuracy: 0.3685 - top-5-accuracy: 0.6669 - val_loss: 14.5645 - val_accuracy: 0.0073 - val_top-5-accuracy: 0.0177\n",
            "Epoch 28/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.4301 - accuracy: 0.3754 - top-5-accuracy: 0.6760 - val_loss: 14.7719 - val_accuracy: 0.0084 - val_top-5-accuracy: 0.0191\n",
            "Epoch 29/100\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 2.4002 - accuracy: 0.3806 - top-5-accuracy: 0.6820 - val_loss: 14.8039 - val_accuracy: 0.0109 - val_top-5-accuracy: 0.0206\n",
            "Epoch 30/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.3671 - accuracy: 0.3877 - top-5-accuracy: 0.6897 - val_loss: 14.6683 - val_accuracy: 0.0092 - val_top-5-accuracy: 0.0188\n",
            "Epoch 31/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 2.3416 - accuracy: 0.3933 - top-5-accuracy: 0.6946 - val_loss: 14.5968 - val_accuracy: 0.0094 - val_top-5-accuracy: 0.0198\n",
            "Epoch 32/100\n",
            "214/214 [==============================] - 79s 368ms/step - loss: 2.3187 - accuracy: 0.3965 - top-5-accuracy: 0.7007 - val_loss: 15.0639 - val_accuracy: 0.0104 - val_top-5-accuracy: 0.0196\n",
            "Epoch 33/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 2.2892 - accuracy: 0.4037 - top-5-accuracy: 0.7046 - val_loss: 14.5585 - val_accuracy: 0.0089 - val_top-5-accuracy: 0.0185\n",
            "Epoch 34/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.2486 - accuracy: 0.4151 - top-5-accuracy: 0.7146 - val_loss: 15.5499 - val_accuracy: 0.0102 - val_top-5-accuracy: 0.0211\n",
            "Epoch 35/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.2259 - accuracy: 0.4169 - top-5-accuracy: 0.7207 - val_loss: 15.3866 - val_accuracy: 0.0089 - val_top-5-accuracy: 0.0195\n",
            "Epoch 36/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 2.2030 - accuracy: 0.4251 - top-5-accuracy: 0.7218 - val_loss: 15.0346 - val_accuracy: 0.0059 - val_top-5-accuracy: 0.0152\n",
            "Epoch 37/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 2.1828 - accuracy: 0.4259 - top-5-accuracy: 0.7276 - val_loss: 15.3747 - val_accuracy: 0.0084 - val_top-5-accuracy: 0.0177\n",
            "Epoch 38/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.1510 - accuracy: 0.4329 - top-5-accuracy: 0.7341 - val_loss: 15.5356 - val_accuracy: 0.0068 - val_top-5-accuracy: 0.0170\n",
            "Epoch 39/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.1285 - accuracy: 0.4393 - top-5-accuracy: 0.7419 - val_loss: 16.0993 - val_accuracy: 0.0068 - val_top-5-accuracy: 0.0165\n",
            "Epoch 40/100\n",
            "214/214 [==============================] - 82s 384ms/step - loss: 2.0982 - accuracy: 0.4461 - top-5-accuracy: 0.7465 - val_loss: 15.6740 - val_accuracy: 0.0117 - val_top-5-accuracy: 0.0201\n",
            "Epoch 41/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.0711 - accuracy: 0.4503 - top-5-accuracy: 0.7516 - val_loss: 16.0152 - val_accuracy: 0.0079 - val_top-5-accuracy: 0.0175\n",
            "Epoch 42/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 2.0598 - accuracy: 0.4565 - top-5-accuracy: 0.7543 - val_loss: 15.5883 - val_accuracy: 0.0099 - val_top-5-accuracy: 0.0181\n",
            "Epoch 43/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 2.0450 - accuracy: 0.4598 - top-5-accuracy: 0.7591 - val_loss: 16.4706 - val_accuracy: 0.0069 - val_top-5-accuracy: 0.0186\n",
            "Epoch 44/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 2.0082 - accuracy: 0.4611 - top-5-accuracy: 0.7673 - val_loss: 16.1639 - val_accuracy: 0.0111 - val_top-5-accuracy: 0.0196\n",
            "Epoch 45/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.9937 - accuracy: 0.4664 - top-5-accuracy: 0.7688 - val_loss: 16.2993 - val_accuracy: 0.0078 - val_top-5-accuracy: 0.0160\n",
            "Epoch 46/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.9768 - accuracy: 0.4694 - top-5-accuracy: 0.7741 - val_loss: 16.4255 - val_accuracy: 0.0081 - val_top-5-accuracy: 0.0185\n",
            "Epoch 47/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.9553 - accuracy: 0.4787 - top-5-accuracy: 0.7777 - val_loss: 16.5338 - val_accuracy: 0.0099 - val_top-5-accuracy: 0.0191\n",
            "Epoch 48/100\n",
            "214/214 [==============================] - 82s 385ms/step - loss: 1.9395 - accuracy: 0.4802 - top-5-accuracy: 0.7792 - val_loss: 16.2838 - val_accuracy: 0.0139 - val_top-5-accuracy: 0.0218\n",
            "Epoch 49/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.9026 - accuracy: 0.4885 - top-5-accuracy: 0.7849 - val_loss: 16.4793 - val_accuracy: 0.0078 - val_top-5-accuracy: 0.0165\n",
            "Epoch 50/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.9005 - accuracy: 0.4883 - top-5-accuracy: 0.7888 - val_loss: 16.6295 - val_accuracy: 0.0087 - val_top-5-accuracy: 0.0188\n",
            "Epoch 51/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.8735 - accuracy: 0.4937 - top-5-accuracy: 0.7933 - val_loss: 16.9691 - val_accuracy: 0.0094 - val_top-5-accuracy: 0.0175\n",
            "Epoch 52/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.8685 - accuracy: 0.4945 - top-5-accuracy: 0.7932 - val_loss: 16.8606 - val_accuracy: 0.0106 - val_top-5-accuracy: 0.0214\n",
            "Epoch 53/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.8420 - accuracy: 0.5007 - top-5-accuracy: 0.7992 - val_loss: 17.2585 - val_accuracy: 0.0089 - val_top-5-accuracy: 0.0183\n",
            "Epoch 54/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.8152 - accuracy: 0.5062 - top-5-accuracy: 0.8042 - val_loss: 17.2954 - val_accuracy: 0.0104 - val_top-5-accuracy: 0.0195\n",
            "Epoch 55/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.8116 - accuracy: 0.5094 - top-5-accuracy: 0.8060 - val_loss: 17.0195 - val_accuracy: 0.0104 - val_top-5-accuracy: 0.0201\n",
            "Epoch 56/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.7946 - accuracy: 0.5133 - top-5-accuracy: 0.8084 - val_loss: 17.2935 - val_accuracy: 0.0109 - val_top-5-accuracy: 0.0206\n",
            "Epoch 57/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.7692 - accuracy: 0.5203 - top-5-accuracy: 0.8128 - val_loss: 17.1844 - val_accuracy: 0.0109 - val_top-5-accuracy: 0.0196\n",
            "Epoch 58/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.7648 - accuracy: 0.5177 - top-5-accuracy: 0.8155 - val_loss: 17.7059 - val_accuracy: 0.0096 - val_top-5-accuracy: 0.0188\n",
            "Epoch 59/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.7498 - accuracy: 0.5237 - top-5-accuracy: 0.8188 - val_loss: 17.2611 - val_accuracy: 0.0086 - val_top-5-accuracy: 0.0186\n",
            "Epoch 60/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.7317 - accuracy: 0.5244 - top-5-accuracy: 0.8204 - val_loss: 17.7598 - val_accuracy: 0.0104 - val_top-5-accuracy: 0.0200\n",
            "Epoch 61/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.7088 - accuracy: 0.5325 - top-5-accuracy: 0.8258 - val_loss: 17.4308 - val_accuracy: 0.0096 - val_top-5-accuracy: 0.0185\n",
            "Epoch 62/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.6912 - accuracy: 0.5364 - top-5-accuracy: 0.8275 - val_loss: 18.4004 - val_accuracy: 0.0092 - val_top-5-accuracy: 0.0191\n",
            "Epoch 63/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.6948 - accuracy: 0.5342 - top-5-accuracy: 0.8282 - val_loss: 17.6374 - val_accuracy: 0.0084 - val_top-5-accuracy: 0.0175\n",
            "Epoch 64/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.6792 - accuracy: 0.5388 - top-5-accuracy: 0.8304 - val_loss: 17.8699 - val_accuracy: 0.0114 - val_top-5-accuracy: 0.0205\n",
            "Epoch 65/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.6648 - accuracy: 0.5412 - top-5-accuracy: 0.8356 - val_loss: 18.2075 - val_accuracy: 0.0101 - val_top-5-accuracy: 0.0178\n",
            "Epoch 66/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.6493 - accuracy: 0.5463 - top-5-accuracy: 0.8360 - val_loss: 18.0245 - val_accuracy: 0.0101 - val_top-5-accuracy: 0.0195\n",
            "Epoch 67/100\n",
            "214/214 [==============================] - 81s 381ms/step - loss: 1.6412 - accuracy: 0.5475 - top-5-accuracy: 0.8400 - val_loss: 18.2230 - val_accuracy: 0.0106 - val_top-5-accuracy: 0.0183\n",
            "Epoch 68/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 1.6285 - accuracy: 0.5533 - top-5-accuracy: 0.8406 - val_loss: 17.8388 - val_accuracy: 0.0120 - val_top-5-accuracy: 0.0188\n",
            "Epoch 69/100\n",
            "214/214 [==============================] - 81s 381ms/step - loss: 1.6123 - accuracy: 0.5567 - top-5-accuracy: 0.8422 - val_loss: 17.6581 - val_accuracy: 0.0102 - val_top-5-accuracy: 0.0200\n",
            "Epoch 70/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.6065 - accuracy: 0.5551 - top-5-accuracy: 0.8436 - val_loss: 18.8833 - val_accuracy: 0.0076 - val_top-5-accuracy: 0.0170\n",
            "Epoch 71/100\n",
            "214/214 [==============================] - 80s 376ms/step - loss: 1.5988 - accuracy: 0.5565 - top-5-accuracy: 0.8449 - val_loss: 18.6502 - val_accuracy: 0.0145 - val_top-5-accuracy: 0.0219\n",
            "Epoch 72/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 1.5870 - accuracy: 0.5605 - top-5-accuracy: 0.8482 - val_loss: 18.3643 - val_accuracy: 0.0082 - val_top-5-accuracy: 0.0183\n",
            "Epoch 73/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.5671 - accuracy: 0.5643 - top-5-accuracy: 0.8499 - val_loss: 18.4821 - val_accuracy: 0.0082 - val_top-5-accuracy: 0.0160\n",
            "Epoch 74/100\n",
            "214/214 [==============================] - 81s 381ms/step - loss: 1.5463 - accuracy: 0.5714 - top-5-accuracy: 0.8543 - val_loss: 19.1675 - val_accuracy: 0.0099 - val_top-5-accuracy: 0.0190\n",
            "Epoch 75/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.5452 - accuracy: 0.5696 - top-5-accuracy: 0.8542 - val_loss: 18.3707 - val_accuracy: 0.0117 - val_top-5-accuracy: 0.0205\n",
            "Epoch 76/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.5312 - accuracy: 0.5750 - top-5-accuracy: 0.8579 - val_loss: 18.6929 - val_accuracy: 0.0111 - val_top-5-accuracy: 0.0195\n",
            "Epoch 77/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.5290 - accuracy: 0.5769 - top-5-accuracy: 0.8560 - val_loss: 18.5741 - val_accuracy: 0.0106 - val_top-5-accuracy: 0.0203\n",
            "Epoch 78/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.5191 - accuracy: 0.5751 - top-5-accuracy: 0.8601 - val_loss: 17.9563 - val_accuracy: 0.0117 - val_top-5-accuracy: 0.0196\n",
            "Epoch 79/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.5004 - accuracy: 0.5803 - top-5-accuracy: 0.8640 - val_loss: 18.8025 - val_accuracy: 0.0106 - val_top-5-accuracy: 0.0188\n",
            "Epoch 80/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.5077 - accuracy: 0.5785 - top-5-accuracy: 0.8604 - val_loss: 18.3606 - val_accuracy: 0.0107 - val_top-5-accuracy: 0.0198\n",
            "Epoch 81/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4925 - accuracy: 0.5845 - top-5-accuracy: 0.8633 - val_loss: 17.8932 - val_accuracy: 0.0096 - val_top-5-accuracy: 0.0173\n",
            "Epoch 82/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4838 - accuracy: 0.5861 - top-5-accuracy: 0.8654 - val_loss: 18.5690 - val_accuracy: 0.0107 - val_top-5-accuracy: 0.0198\n",
            "Epoch 83/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4779 - accuracy: 0.5851 - top-5-accuracy: 0.8666 - val_loss: 18.8691 - val_accuracy: 0.0129 - val_top-5-accuracy: 0.0218\n",
            "Epoch 84/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4763 - accuracy: 0.5859 - top-5-accuracy: 0.8676 - val_loss: 18.8362 - val_accuracy: 0.0094 - val_top-5-accuracy: 0.0181\n",
            "Epoch 85/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.4486 - accuracy: 0.5928 - top-5-accuracy: 0.8721 - val_loss: 18.5627 - val_accuracy: 0.0117 - val_top-5-accuracy: 0.0211\n",
            "Epoch 86/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4536 - accuracy: 0.5928 - top-5-accuracy: 0.8712 - val_loss: 18.7802 - val_accuracy: 0.0120 - val_top-5-accuracy: 0.0211\n",
            "Epoch 87/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4371 - accuracy: 0.5964 - top-5-accuracy: 0.8731 - val_loss: 18.4810 - val_accuracy: 0.0115 - val_top-5-accuracy: 0.0193\n",
            "Epoch 88/100\n",
            "214/214 [==============================] - 81s 379ms/step - loss: 1.4351 - accuracy: 0.5967 - top-5-accuracy: 0.8733 - val_loss: 18.8675 - val_accuracy: 0.0073 - val_top-5-accuracy: 0.0148\n",
            "Epoch 89/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.4396 - accuracy: 0.5946 - top-5-accuracy: 0.8759 - val_loss: 18.6873 - val_accuracy: 0.0104 - val_top-5-accuracy: 0.0206\n",
            "Epoch 90/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4225 - accuracy: 0.5996 - top-5-accuracy: 0.8751 - val_loss: 18.6486 - val_accuracy: 0.0101 - val_top-5-accuracy: 0.0183\n",
            "Epoch 91/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.4283 - accuracy: 0.6004 - top-5-accuracy: 0.8741 - val_loss: 18.7686 - val_accuracy: 0.0092 - val_top-5-accuracy: 0.0186\n",
            "Epoch 92/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.3988 - accuracy: 0.6071 - top-5-accuracy: 0.8800 - val_loss: 19.3313 - val_accuracy: 0.0107 - val_top-5-accuracy: 0.0190\n",
            "Epoch 93/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 1.3945 - accuracy: 0.6083 - top-5-accuracy: 0.8795 - val_loss: 18.9692 - val_accuracy: 0.0111 - val_top-5-accuracy: 0.0198\n",
            "Epoch 94/100\n",
            "214/214 [==============================] - 79s 369ms/step - loss: 1.3987 - accuracy: 0.6052 - top-5-accuracy: 0.8824 - val_loss: 18.7796 - val_accuracy: 0.0119 - val_top-5-accuracy: 0.0206\n",
            "Epoch 95/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.3962 - accuracy: 0.6064 - top-5-accuracy: 0.8803 - val_loss: 18.6846 - val_accuracy: 0.0084 - val_top-5-accuracy: 0.0178\n",
            "Epoch 96/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.3809 - accuracy: 0.6106 - top-5-accuracy: 0.8822 - val_loss: 18.8883 - val_accuracy: 0.0091 - val_top-5-accuracy: 0.0191\n",
            "Epoch 97/100\n",
            "214/214 [==============================] - 79s 370ms/step - loss: 1.3722 - accuracy: 0.6136 - top-5-accuracy: 0.8829 - val_loss: 18.8454 - val_accuracy: 0.0117 - val_top-5-accuracy: 0.0224\n",
            "Epoch 98/100\n",
            "214/214 [==============================] - 81s 381ms/step - loss: 1.3760 - accuracy: 0.6123 - top-5-accuracy: 0.8836 - val_loss: 19.2474 - val_accuracy: 0.0102 - val_top-5-accuracy: 0.0210\n",
            "Epoch 99/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.3641 - accuracy: 0.6146 - top-5-accuracy: 0.8847 - val_loss: 19.0753 - val_accuracy: 0.0119 - val_top-5-accuracy: 0.0218\n",
            "Epoch 100/100\n",
            "214/214 [==============================] - 81s 380ms/step - loss: 1.3617 - accuracy: 0.6173 - top-5-accuracy: 0.8871 - val_loss: 18.2171 - val_accuracy: 0.0106 - val_top-5-accuracy: 0.0190\n",
            "474/474 [==============================] - 11s 24ms/step - loss: 19.0585 - accuracy: 0.0000e+00 - top-5-accuracy: 0.0000e+00\n",
            "Test accuracy: 0.0%\n",
            "Test top 5 accuracy: 0.0%\n"
          ]
        }
      ],
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_val, y_val)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoL3wjshTWuN"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "saving_path_new = \"/content/drive/MyDrive/Colab Notebooks/kaggle_tarea2/vit_classifier_model.h5\"\n",
        "vit_classifier.save(saving_path_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkNegNYatjlY",
        "outputId": "2811909f-f4fc-42f1-b592-3430b5ca6683"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model js\n",
        "saving_path_new = \"/content/drive/MyDrive/kaggle_tarea2/vit_classifier_model_imgsize_72.h5\"\n",
        "vit_classifier.save(saving_path_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmKos8o7vky4"
      },
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXcSZ5Wlu4d1",
        "outputId": "8264f587-fa82-48ee-927c-07cad6b3c891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "474/474 [==============================] - 12s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "# Register the custom layers\n",
        "tf.keras.utils.get_custom_objects()['Patches'] = Patches\n",
        "tf.keras.utils.get_custom_objects()['PatchEncoder'] = PatchEncoder\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model(saving_path_new)\n",
        "\n",
        "# Now you can use 'loaded_model' for predictions\n",
        "predictions = loaded_model.predict(x_val)  # Replace 'new_data' with your input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGTyUSBs4OMm",
        "outputId": "b633ebdb-5bce-4a8a-fe8d-3c1ebaaef5f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15152, 101)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of predictions will be (number of pictures of validation set, 101 because of classes)\n",
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKrsbYyY4tx1",
        "outputId": "d65a0402-f35f-4444-dbda-bf44f1792152"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 74],\n",
              "       [ 24],\n",
              "       [ 29],\n",
              "       ...,\n",
              "       [ 40],\n",
              "       [ 98],\n",
              "       [100]], dtype=int32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assuming 'predictions' is your (number of pictures of validation set, 101) array\n",
        "num_samples = predictions.shape[0]  # Number of samples\n",
        "\n",
        "predicted_classes = np.zeros((num_samples, 1), dtype=np.int32)\n",
        "\n",
        "for i in range(num_samples):\n",
        "    predicted_classes[i, 0] = np.argmax(predictions[i])\n",
        "\n",
        "# 'predicted_classes' is now a (number of pictures of validation set, 1) array with the predicted class indices\n",
        "predicted_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiFhMEb4Zsk"
      },
      "source": [
        "#### Visualization of just first image of validation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Por error se ejecutó cuando no se debió, pero no es relevante)"
      ],
      "metadata": {
        "id": "pmBXUUgE0JMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "aA10yxhW1Ud1",
        "outputId": "af4f82b6-758b-47c1-f77c-c5a2460dd2bd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-40464c0d8c41>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming x_val is your 4D image array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_id\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Select the first image from the 4D array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Rescale the pixel values to the [0, 1] range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_val' is not defined"
          ]
        }
      ],
      "source": [
        "# Assuming x_val is your 4D image array\n",
        "pred_id = 0\n",
        "image_to_plot = x_val[pred_id]  # Select the first image from the 4D array\n",
        "\n",
        "# Rescale the pixel values to the [0, 1] range\n",
        "image_to_plot = image_to_plot / 255.0  # If the values are in [0, 255]\n",
        "\n",
        "plt.imshow(image_to_plot)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Assuming 'predictions[0]' is your array\n",
        "class_index = np.argmax(predictions[pred_id])\n",
        "\n",
        "# 'class_index' now contains the index of the class with the highest score\n",
        "print(f\"The predicted class is: {class_index}\")\n",
        "print(f\"Dish:\",dish_dict[str(class_index)])\n",
        "print(f\"Dish_real:\",dish_dict[str(y_train[pred_id][0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "kWIVkGXZTiPo",
        "outputId": "67f23860-55cd-43d9-f85f-189ad4e22722"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-e6ba70fab5f2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming x_val is your 4D image array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_id\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Select the first image from the 4D array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Rescale the pixel values to the [0, 1] range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ],
      "source": [
        "# Assuming x_val is your 4D image array\n",
        "pred_id = 0\n",
        "image_to_plot = x_train[pred_id]  # Select the first image from the 4D array\n",
        "\n",
        "# Rescale the pixel values to the [0, 1] range\n",
        "image_to_plot = image_to_plot / 255.0  # If the values are in [0, 255]\n",
        "\n",
        "plt.imshow(image_to_plot)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Assuming 'predictions[0]' is your array\n",
        "class_index = np.argmax(predictions[pred_id])\n",
        "\n",
        "# 'class_index' now contains the index of the class with the highest score\n",
        "print(f\"The predicted class is: {class_index}\")\n",
        "print(f\"Dish_predicted:\",dish_dict[str(class_index)])\n",
        "print(f\"Dish_real:\",dish_dict[str(y_train[pred_id][0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OswDRypgW-lI"
      },
      "outputs": [],
      "source": [
        "# Load hierarchy dictionary\n",
        "hierarchy_dict = {\n",
        "    \"salad\": {\n",
        "        \"0\": \"seaweed_salad\",\n",
        "        \"1\": \"beet_salad\",\n",
        "        \"2\": \"caesar_salad\",\n",
        "        \"3\": \"caprese_salad\",\n",
        "        \"4\": \"greek_salad\"\n",
        "    },\n",
        "    \"dessert\": {\n",
        "        \"0\": \"apple_pie\",\n",
        "        \"1\": \"baklava\",\n",
        "        \"2\": \"beignets\",\n",
        "        \"3\": \"bread_pudding\",\n",
        "        \"4\": \"cannoli\",\n",
        "        \"5\": \"carrot_cake\",\n",
        "        \"6\": \"cheesecake\",\n",
        "        \"7\": \"chocolate_cake\",\n",
        "        \"8\": \"chocolate_mousse\",\n",
        "        \"9\": \"churros\",\n",
        "        \"10\": \"creme_brulee\",\n",
        "        \"11\": \"cup_cakes\",\n",
        "        \"12\": \"donuts\",\n",
        "        \"13\": \"frozen_yogurt\",\n",
        "        \"14\": \"ice_cream\",\n",
        "        \"15\": \"macarons\",\n",
        "        \"16\": \"panna_cotta\",\n",
        "        \"17\": \"red_velvet_cake\",\n",
        "        \"18\": \"strawberry_shortcake\",\n",
        "        \"19\": \"tiramisu\",\n",
        "        \"20\": \"waffles\"\n",
        "    },\n",
        "    \"main_dish\": {\n",
        "        \"0\": \"baby_back_ribs\",\n",
        "        \"1\": \"beef_carpaccio\",\n",
        "        \"2\": \"beef_tartare\",\n",
        "        \"3\": \"bibimbap\",\n",
        "        \"4\": \"breakfast_burrito\",\n",
        "        \"5\": \"bruschetta\",\n",
        "        \"6\": \"ceviche\",\n",
        "        \"7\": \"cheese_plate\",\n",
        "        \"8\": \"chicken_curry\",\n",
        "        \"9\": \"chicken_quesadilla\",\n",
        "        \"10\": \"chicken_wings\",\n",
        "        \"11\": \"clam_chowder\",\n",
        "        \"12\": \"club_sandwich\",\n",
        "        \"13\": \"crab_cakes\",\n",
        "        \"14\": \"croque_madame\",\n",
        "        \"15\": \"deviled_eggs\",\n",
        "        \"16\": \"dumplings\",\n",
        "        \"17\": \"edamame\",\n",
        "        \"18\": \"eggs_benedict\",\n",
        "        \"19\": \"escargots\",\n",
        "        \"20\": \"falafel\",\n",
        "        \"21\": \"filet_mignon\",\n",
        "        \"22\": \"fish_and_chips\",\n",
        "        \"23\": \"foie_gras\",\n",
        "        \"24\": \"french_fries\",\n",
        "        \"25\": \"french_onion_soup\",\n",
        "        \"26\": \"french_toast\",\n",
        "        \"27\": \"fried_calamari\",\n",
        "        \"28\": \"fried_rice\",\n",
        "        \"29\": \"garlic_bread\",\n",
        "        \"30\": \"gnocchi\",\n",
        "        \"31\": \"grilled_cheese_sandwich\",\n",
        "        \"32\": \"grilled_salmon\",\n",
        "        \"33\": \"guacamole\",\n",
        "        \"34\": \"gyoza\",\n",
        "        \"35\": \"hamburger\",\n",
        "        \"36\": \"hot_and_sour_soup\",\n",
        "        \"37\": \"hot_dog\",\n",
        "        \"38\": \"huevos_rancheros\",\n",
        "        \"39\": \"hummus\",\n",
        "        \"40\": \"lasagna\",\n",
        "        \"41\": \"lobster_bisque\",\n",
        "        \"42\": \"lobster_roll_sandwich\",\n",
        "        \"43\": \"macaroni_and_cheese\",\n",
        "        \"44\": \"miso_soup\",\n",
        "        \"45\": \"mussels\",\n",
        "        \"46\": \"nachos\",\n",
        "        \"47\": \"omelette\",\n",
        "        \"48\": \"onion_rings\",\n",
        "        \"49\": \"oysters\",\n",
        "        \"50\": \"pad_thai\",\n",
        "        \"51\": \"paella\",\n",
        "        \"52\": \"pancakes\",\n",
        "        \"53\": \"peking_duck\",\n",
        "        \"54\": \"pho\",\n",
        "        \"55\": \"pizza\",\n",
        "        \"56\": \"pork_chop\",\n",
        "        \"57\": \"poutine\",\n",
        "        \"58\": \"prime_rib\",\n",
        "        \"59\": \"pulled_pork_sandwich\",\n",
        "        \"60\": \"ramen\",\n",
        "        \"61\": \"ravioli\",\n",
        "        \"62\": \"risotto\",\n",
        "        \"63\": \"samosa\",\n",
        "        \"64\": \"sashimi\",\n",
        "        \"65\": \"scallops\",\n",
        "        \"66\": \"shrimp_and_grits\",\n",
        "        \"67\": \"spaghetti_bolognese\",\n",
        "        \"68\": \"spaghetti_carbonara\",\n",
        "        \"69\": \"spring_rolls\",\n",
        "        \"70\": \"steak\",\n",
        "        \"71\": \"sushi\",\n",
        "        \"72\": \"tacos\",\n",
        "        \"73\": \"takoyaki\",\n",
        "        \"74\": \"tuna_tartare\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJmDFCqoYGFe"
      },
      "outputs": [],
      "source": [
        "# Load food categories dictionary with 3 superclasses\n",
        "food_categories_dict = {\n",
        "    \"0\": \"salad\",\n",
        "    \"1\": \"dessert\",\n",
        "    \"2\": \"main_dish\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hmaX9IsoVr6R",
        "outputId": "b3314a5c-385b-4ef3-87d2-a1ef28baf877"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'salad'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "findOuterKey(hierarchy_dict, dish_dict[str(class_index)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF6dMk6BDm1M"
      },
      "outputs": [],
      "source": [
        "def preprocess_image_test(path_images, target_tuple, image_size, show_images):\n",
        "    # Recuperar la lista de nombres de archivo de las imágenes en el directorio\n",
        "    image_paths = [os.path.join(path_images, f) for f in os.listdir(path_images) if os.path.isfile(os.path.join(path_images, f))]\n",
        "\n",
        "    images, targets = [], []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Cargamos la imagen\n",
        "        image = keras.utils.load_img(image_path)\n",
        "\n",
        "        # Reescalamos la imagen\n",
        "        image = image.resize((image_size, image_size))\n",
        "\n",
        "        # Convertimos la imagen a un array y la almacenamos en la lista\n",
        "        to_array = keras.utils.img_to_array(image)\n",
        "        images.append(to_array)\n",
        "\n",
        "        # Agregamos targets normalizados a la lista\n",
        "        targets.append(target_tuple)\n",
        "\n",
        "        # Switch para visualizar imágenes en el run\n",
        "        if show_images == 1:\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')  # Apagar etiquetas y marcas de los ejes\n",
        "            plt.show()\n",
        "    '''\n",
        "    # iteramos sobre las imagenes\n",
        "    imageRange = len(image_paths) # maximo\n",
        "    #print(imageRange)\n",
        "\n",
        "    for i in range(0, imageRange): # i = 0, 1, ... , 750 (source full training independent of secret test)\n",
        "\n",
        "        #print(path_images)\n",
        "\n",
        "        # cargamos la imagen\n",
        "        image = keras.utils.load_img(path_images + \"/\" + image_paths[i]) # <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=427x207 at 0x7CD26E127370>\n",
        "\n",
        "        # obtenemos el tamaño de la imagen\n",
        "        #(w, h) = image.size[:2]\n",
        "\n",
        "        # reescalamos la imagen\n",
        "        image = image.resize((image_size, image_size))\n",
        "\n",
        "        # convertimos la imagen a un array y la almacenamos en la lista\n",
        "        to_array = keras.utils.img_to_array(image)\n",
        "        # to_array = to_array/255. # normalization of array not done in keras.io\n",
        "        images.append(to_array)\n",
        "\n",
        "        # Agregamos targets normalizados a la lista\n",
        "        targets.append(target_tuple)\n",
        "\n",
        "        # Switch para visualizar imagenes en el run\n",
        "        if show_images == 1:\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')  # Turn off axis labels and ticks\n",
        "            plt.show()\n",
        "    '''\n",
        "\n",
        "    # Construir las rutas de las imágenes en el formato deseado\n",
        "    formatted_image_paths = [os.path.join(\"images\", os.path.basename(path_images), os.path.basename(image_path)) for image_path in image_paths]\n",
        "\n",
        "    return images, targets, formatted_image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiQu-sYDDCTt",
        "outputId": "c4908c37-37bc-48ac-a66d-b0f36319e2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25250, 32, 32, 3)\n",
            "(25250,)\n"
          ]
        }
      ],
      "source": [
        "# Recorrer carpetas de training\n",
        "#source_folder = \"/content/drive/MyDrive/Colab Notebooks/kaggle_tarea2/images_train/\"\n",
        "source_folder = \"/content/drive/MyDrive/kaggle_tarea2/images_test/\"\n",
        "\n",
        "# Initialize full lists\n",
        "test_images, test_targets, test_all_paths = [], [], []\n",
        "\n",
        "for foldername in os.listdir(source_folder):\n",
        "\n",
        "    # Retain dish key in dish_dict\n",
        "    dish_dict_key = getKeyByValue(dish_dict, foldername)\n",
        "    dish_dict_key_norm = int(dish_dict_key) # normalization not done in keras.io\n",
        "\n",
        "    # Retain food categorie key in hierarchy_dict\n",
        "    #food_categorie_key_str = findOuterKey(hierarchy_dict, foldername)\n",
        "\n",
        "    # Retain food categorie Number in food_categories_dict\n",
        "    #food_categorie_key = getKeyByValue(food_categories_dict, food_categorie_key_str)\n",
        "    #food_categorie_key = int(food_categorie_key) # convert to int\n",
        "\n",
        "    # CASE 0: Multiple targets\n",
        "    # dish: dish_num / dish_num normalized / food_categorie_str / food_categorie_key\n",
        "    #print(foldername, \": \", dish_dict_key, dish_dict_key_norm, food_categorie_key_str, food_categorie_key)\n",
        "\n",
        "    # CASE 1: Simplefied (1 target)\n",
        "    # print(foldername, \": \", dish_dict_key, dish_dict_key_norm) # avoid printing for speed\n",
        "\n",
        "    # Collect training folder full path of preprocessing\n",
        "    path_images = os.path.join(source_folder, foldername) # /content/drive/MyDrive/Colab Notebooks/kaggle_tarea2/images_train/apple_pie_train\n",
        "\n",
        "    # Apply preprocess fun\n",
        "    image_size = 32\n",
        "    show_images = 0 # 1: show, 0: not show\n",
        "    target_tuple = dish_dict_key_norm # according to certain dish & normalized\n",
        "    images, targets, paths = preprocess_image_test(path_images, target_tuple, image_size, show_images)\n",
        "\n",
        "    test_all_paths.extend(paths)\n",
        "    test_images.extend(images)\n",
        "    test_targets.extend(targets)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "test_images = np.array(test_images)\n",
        "test_targets = np.array(test_targets)\n",
        "\n",
        "# convertimos las listas a arrays\n",
        "(test_x), (test_y) = (np.asarray(test_images), np.asarray(test_targets))\n",
        "\n",
        "# show shape results\n",
        "print(test_images.shape)\n",
        "print(test_targets.shape)\n",
        "\n",
        "# save memory\n",
        "#del test_images\n",
        "del test_targets\n",
        "\n",
        "# reshape vectors\n",
        "test_y = test_y.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBoy2N20HI2N",
        "outputId": "7708929b-3b59-4cdc-db22-9b433f076c16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25250, 32, 32, 3)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EFYCuUvUc79",
        "outputId": "9ce37f42-8701-4ece-835a-50ccbc69c703"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25250"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_all_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l5eH6UWUqHp3",
        "outputId": "e4e40640-f7c5-4be2-fda9-d4b4419ebcba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'images/breakfast_burrito/1360734.jpg'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_all_paths[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6ffdg9_e_TJ"
      },
      "outputs": [],
      "source": [
        "keras.utils.get_custom_objects().update({\"Patches\": Patches, \"PatchEncoder\": PatchEncoder})\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/kaggle_tarea2/vit_classifier_model_imgsize_72.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGQrIlFUhoh4",
        "outputId": "f48f5769-ccbd-45ff-ff31-085f3b3cf940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "790/790 [==============================] - 465s 586ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions_kaggle = model.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVVn7Hj-kQ6b",
        "outputId": "1239bfaf-370c-4313-94c6-4c49933faa22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25250"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_kaggle.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D3W0Jqbj0F2"
      },
      "outputs": [],
      "source": [
        "valores_kaggle = []\n",
        "for i in range(predictions_kaggle.shape[0]):\n",
        "    valores_kaggle.append(np.argmax(predictions_kaggle[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOVMb0O-3RSq",
        "outputId": "2fa40434-a06f-4a85-978f-27b732875a03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[96,\n",
              " 24,\n",
              " 100,\n",
              " 10,\n",
              " 44,\n",
              " 26,\n",
              " 23,\n",
              " 22,\n",
              " 36,\n",
              " 65,\n",
              " 72,\n",
              " 1,\n",
              " 61,\n",
              " 20,\n",
              " 19,\n",
              " 13,\n",
              " 95,\n",
              " 69,\n",
              " 57,\n",
              " 26,\n",
              " 2,\n",
              " 88,\n",
              " 65,\n",
              " 94,\n",
              " 31,\n",
              " 20,\n",
              " 2,\n",
              " 39,\n",
              " 20,\n",
              " 100,\n",
              " 81,\n",
              " 22,\n",
              " 96,\n",
              " 63,\n",
              " 2,\n",
              " 23,\n",
              " 88,\n",
              " 60,\n",
              " 52,\n",
              " 23,\n",
              " 23,\n",
              " 30,\n",
              " 52,\n",
              " 36,\n",
              " 23,\n",
              " 23,\n",
              " 70,\n",
              " 51,\n",
              " 76,\n",
              " 60,\n",
              " 96,\n",
              " 76,\n",
              " 76,\n",
              " 65,\n",
              " 95,\n",
              " 60,\n",
              " 47,\n",
              " 1,\n",
              " 51,\n",
              " 52,\n",
              " 69,\n",
              " 22,\n",
              " 60,\n",
              " 23,\n",
              " 63,\n",
              " 47,\n",
              " 59,\n",
              " 98,\n",
              " 1,\n",
              " 82,\n",
              " 86,\n",
              " 26,\n",
              " 56,\n",
              " 51,\n",
              " 22,\n",
              " 88,\n",
              " 69,\n",
              " 81,\n",
              " 65,\n",
              " 60,\n",
              " 70,\n",
              " 23,\n",
              " 23,\n",
              " 70,\n",
              " 2,\n",
              " 65,\n",
              " 49,\n",
              " 22,\n",
              " 86,\n",
              " 23,\n",
              " 99,\n",
              " 1,\n",
              " 88,\n",
              " 60,\n",
              " 65,\n",
              " 59,\n",
              " 63,\n",
              " 52,\n",
              " 20,\n",
              " 26,\n",
              " 63,\n",
              " 61,\n",
              " 63,\n",
              " 60,\n",
              " 78,\n",
              " 23,\n",
              " 63,\n",
              " 13,\n",
              " 73,\n",
              " 99,\n",
              " 74,\n",
              " 98,\n",
              " 47,\n",
              " 77,\n",
              " 60,\n",
              " 86,\n",
              " 21,\n",
              " 68,\n",
              " 100,\n",
              " 22,\n",
              " 23,\n",
              " 85,\n",
              " 2,\n",
              " 12,\n",
              " 23,\n",
              " 83,\n",
              " 1,\n",
              " 96,\n",
              " 1,\n",
              " 43,\n",
              " 85,\n",
              " 98,\n",
              " 40,\n",
              " 23,\n",
              " 57,\n",
              " 81,\n",
              " 76,\n",
              " 98,\n",
              " 45,\n",
              " 57,\n",
              " 24,\n",
              " 70,\n",
              " 98,\n",
              " 51,\n",
              " 22,\n",
              " 60,\n",
              " 49,\n",
              " 91,\n",
              " 52,\n",
              " 22,\n",
              " 65,\n",
              " 20,\n",
              " 78,\n",
              " 13,\n",
              " 49,\n",
              " 22,\n",
              " 20,\n",
              " 60,\n",
              " 36,\n",
              " 69,\n",
              " 52,\n",
              " 22,\n",
              " 1,\n",
              " 22,\n",
              " 47,\n",
              " 12,\n",
              " 22,\n",
              " 36,\n",
              " 1,\n",
              " 12,\n",
              " 60,\n",
              " 51,\n",
              " 30,\n",
              " 1,\n",
              " 23,\n",
              " 96,\n",
              " 63,\n",
              " 23,\n",
              " 100,\n",
              " 2,\n",
              " 69,\n",
              " 23,\n",
              " 63,\n",
              " 28,\n",
              " 70,\n",
              " 4,\n",
              " 67,\n",
              " 23,\n",
              " 23,\n",
              " 1,\n",
              " 36,\n",
              " 36,\n",
              " 12,\n",
              " 23,\n",
              " 60,\n",
              " 23,\n",
              " 20,\n",
              " 1,\n",
              " 3,\n",
              " 22,\n",
              " 59,\n",
              " 89,\n",
              " 77,\n",
              " 73,\n",
              " 1,\n",
              " 23,\n",
              " 39,\n",
              " 36,\n",
              " 23,\n",
              " 83,\n",
              " 12,\n",
              " 36,\n",
              " 59,\n",
              " 56,\n",
              " 23,\n",
              " 63,\n",
              " 65,\n",
              " 22,\n",
              " 60,\n",
              " 81,\n",
              " 23,\n",
              " 23,\n",
              " 92,\n",
              " 73,\n",
              " 81,\n",
              " 56,\n",
              " 52,\n",
              " 51,\n",
              " 65,\n",
              " 59,\n",
              " 78,\n",
              " 28,\n",
              " 70,\n",
              " 86,\n",
              " 44,\n",
              " 86,\n",
              " 65,\n",
              " 23,\n",
              " 23,\n",
              " 55,\n",
              " 31,\n",
              " 81,\n",
              " 51,\n",
              " 63,\n",
              " 51,\n",
              " 28,\n",
              " 36,\n",
              " 44,\n",
              " 98,\n",
              " 51,\n",
              " 22,\n",
              " 76,\n",
              " 52,\n",
              " 49,\n",
              " 21,\n",
              " 21,\n",
              " 24,\n",
              " 69,\n",
              " 21,\n",
              " 49,\n",
              " 52,\n",
              " 21,\n",
              " 89,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 100,\n",
              " 60,\n",
              " 22,\n",
              " 72,\n",
              " 21,\n",
              " 21,\n",
              " 81,\n",
              " 13,\n",
              " 21,\n",
              " 20,\n",
              " 1,\n",
              " 43,\n",
              " 21,\n",
              " 1,\n",
              " 21,\n",
              " 1,\n",
              " 21,\n",
              " 21,\n",
              " 4,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 55,\n",
              " 30,\n",
              " 49,\n",
              " 5,\n",
              " 26,\n",
              " 36,\n",
              " 21,\n",
              " 30,\n",
              " 12,\n",
              " 72,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 78,\n",
              " 39,\n",
              " 21,\n",
              " 100,\n",
              " 1,\n",
              " 21,\n",
              " 26,\n",
              " 26,\n",
              " 60,\n",
              " 47,\n",
              " 21,\n",
              " 21,\n",
              " 81,\n",
              " 1,\n",
              " 51,\n",
              " 39,\n",
              " 21,\n",
              " 1,\n",
              " 29,\n",
              " 12,\n",
              " 21,\n",
              " 21,\n",
              " 22,\n",
              " 1,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 28,\n",
              " 73,\n",
              " 88,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 60,\n",
              " 28,\n",
              " 73,\n",
              " 86,\n",
              " 52,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 88,\n",
              " 1,\n",
              " 21,\n",
              " 20,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 100,\n",
              " 21,\n",
              " 51,\n",
              " 39,\n",
              " 30,\n",
              " 51,\n",
              " 31,\n",
              " 51,\n",
              " 21,\n",
              " 21,\n",
              " 49,\n",
              " 73,\n",
              " 19,\n",
              " 73,\n",
              " 21,\n",
              " 39,\n",
              " 21,\n",
              " 51,\n",
              " 21,\n",
              " 81,\n",
              " 21,\n",
              " 100,\n",
              " 1,\n",
              " 52,\n",
              " 28,\n",
              " 36,\n",
              " 21,\n",
              " 76,\n",
              " 8,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 51,\n",
              " 39,\n",
              " 30,\n",
              " 63,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 51,\n",
              " 73,\n",
              " 39,\n",
              " 21,\n",
              " 49,\n",
              " 1,\n",
              " 1,\n",
              " 100,\n",
              " 36,\n",
              " 77,\n",
              " 26,\n",
              " 21,\n",
              " 99,\n",
              " 76,\n",
              " 77,\n",
              " 21,\n",
              " 1,\n",
              " 51,\n",
              " 21,\n",
              " 26,\n",
              " 21,\n",
              " 20,\n",
              " 73,\n",
              " 21,\n",
              " 52,\n",
              " 21,\n",
              " 1,\n",
              " 12,\n",
              " 21,\n",
              " 63,\n",
              " 43,\n",
              " 21,\n",
              " 81,\n",
              " 21,\n",
              " 43,\n",
              " 52,\n",
              " 36,\n",
              " 21,\n",
              " 52,\n",
              " 85,\n",
              " 28,\n",
              " 86,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 52,\n",
              " 76,\n",
              " 21,\n",
              " 21,\n",
              " 21,\n",
              " 30,\n",
              " 21,\n",
              " 21,\n",
              " 49,\n",
              " 1,\n",
              " 1,\n",
              " 21,\n",
              " 21,\n",
              " 1,\n",
              " 43,\n",
              " 21,\n",
              " 51,\n",
              " 1,\n",
              " 3,\n",
              " 21,\n",
              " 21,\n",
              " 36,\n",
              " 92,\n",
              " 21,\n",
              " 24,\n",
              " 63,\n",
              " 21,\n",
              " 1,\n",
              " 52,\n",
              " 68,\n",
              " 51,\n",
              " 100,\n",
              " 1,\n",
              " 21,\n",
              " 8,\n",
              " 21,\n",
              " 73,\n",
              " 73,\n",
              " 88,\n",
              " 100,\n",
              " 21,\n",
              " 52,\n",
              " 43,\n",
              " 21,\n",
              " 1,\n",
              " 21,\n",
              " 21,\n",
              " 72,\n",
              " 21,\n",
              " 39,\n",
              " 72,\n",
              " 56,\n",
              " 52,\n",
              " 52,\n",
              " 8,\n",
              " 73,\n",
              " 21,\n",
              " 21,\n",
              " 72,\n",
              " 49,\n",
              " 1,\n",
              " 21,\n",
              " 21,\n",
              " 86,\n",
              " 13,\n",
              " 63,\n",
              " 52,\n",
              " 60,\n",
              " 60,\n",
              " 20,\n",
              " 69,\n",
              " 77,\n",
              " 45,\n",
              " 52,\n",
              " 97,\n",
              " 16,\n",
              " 70,\n",
              " 70,\n",
              " 20,\n",
              " 70,\n",
              " 61,\n",
              " 40,\n",
              " 100,\n",
              " 39,\n",
              " 86,\n",
              " 100,\n",
              " 52,\n",
              " 22,\n",
              " 91,\n",
              " 52,\n",
              " 12,\n",
              " 92,\n",
              " 31,\n",
              " 22,\n",
              " 91,\n",
              " 40,\n",
              " 24,\n",
              " 45,\n",
              " 70,\n",
              " 70,\n",
              " 78,\n",
              " 70,\n",
              " 45,\n",
              " 40,\n",
              " 51,\n",
              " 13,\n",
              " 40,\n",
              " 31,\n",
              " 26,\n",
              " 39,\n",
              " 44,\n",
              " 82,\n",
              " 52,\n",
              " 69,\n",
              " 52,\n",
              " 85,\n",
              " 100,\n",
              " 45,\n",
              " 52,\n",
              " 45,\n",
              " 45,\n",
              " 20,\n",
              " 22,\n",
              " 13,\n",
              " 92,\n",
              " 52,\n",
              " 52,\n",
              " 43,\n",
              " 52,\n",
              " 69,\n",
              " 40,\n",
              " 28,\n",
              " 45,\n",
              " 40,\n",
              " 69,\n",
              " 70,\n",
              " 95,\n",
              " 95,\n",
              " 45,\n",
              " 52,\n",
              " 91,\n",
              " 69,\n",
              " 60,\n",
              " 70,\n",
              " 1,\n",
              " 52,\n",
              " 70,\n",
              " 13,\n",
              " 91,\n",
              " 69,\n",
              " 52,\n",
              " 40,\n",
              " 33,\n",
              " 91,\n",
              " 13,\n",
              " 63,\n",
              " 46,\n",
              " 45,\n",
              " 82,\n",
              " 69,\n",
              " 60,\n",
              " 91,\n",
              " 12,\n",
              " 100,\n",
              " 6,\n",
              " 59,\n",
              " 44,\n",
              " 36,\n",
              " 40,\n",
              " 52,\n",
              " 60,\n",
              " 70,\n",
              " 88,\n",
              " 69,\n",
              " 22,\n",
              " 91,\n",
              " 69,\n",
              " 70,\n",
              " 20,\n",
              " 45,\n",
              " 45,\n",
              " 51,\n",
              " 30,\n",
              " 69,\n",
              " 70,\n",
              " 65,\n",
              " 52,\n",
              " 69,\n",
              " 40,\n",
              " 24,\n",
              " 70,\n",
              " 69,\n",
              " 70,\n",
              " 33,\n",
              " 81,\n",
              " 85,\n",
              " 70,\n",
              " 69,\n",
              " 73,\n",
              " 40,\n",
              " 52,\n",
              " 91,\n",
              " 52,\n",
              " 52,\n",
              " 13,\n",
              " 45,\n",
              " 22,\n",
              " 70,\n",
              " 52,\n",
              " 40,\n",
              " 85,\n",
              " 85,\n",
              " 69,\n",
              " 43,\n",
              " 45,\n",
              " 69,\n",
              " 45,\n",
              " 100,\n",
              " 62,\n",
              " 88,\n",
              " 91,\n",
              " 70,\n",
              " 2,\n",
              " 81,\n",
              " 69,\n",
              " 46,\n",
              " 20,\n",
              " 69,\n",
              " 81,\n",
              " 45,\n",
              " 13,\n",
              " 52,\n",
              " 43,\n",
              " 46,\n",
              " 52,\n",
              " 69,\n",
              " 45,\n",
              " 36,\n",
              " 69,\n",
              " 91,\n",
              " 52,\n",
              " 34,\n",
              " 40,\n",
              " 52,\n",
              " 52,\n",
              " 60,\n",
              " 40,\n",
              " 26,\n",
              " 69,\n",
              " 100,\n",
              " 52,\n",
              " 2,\n",
              " 45,\n",
              " 40,\n",
              " 52,\n",
              " 81,\n",
              " 69,\n",
              " 85,\n",
              " 45,\n",
              " 40,\n",
              " 69,\n",
              " 69,\n",
              " 23,\n",
              " 69,\n",
              " 40,\n",
              " 45,\n",
              " 70,\n",
              " 13,\n",
              " 52,\n",
              " 26,\n",
              " 40,\n",
              " 13,\n",
              " 30,\n",
              " 69,\n",
              " 36,\n",
              " 100,\n",
              " 52,\n",
              " 0,\n",
              " 52,\n",
              " 69,\n",
              " 40,\n",
              " 52,\n",
              " 91,\n",
              " 73,\n",
              " 60,\n",
              " 59,\n",
              " 52,\n",
              " 91,\n",
              " 26,\n",
              " 91,\n",
              " 61,\n",
              " 40,\n",
              " 69,\n",
              " 91,\n",
              " 44,\n",
              " 52,\n",
              " 40,\n",
              " 44,\n",
              " 34,\n",
              " 69,\n",
              " 24,\n",
              " 31,\n",
              " 45,\n",
              " 1,\n",
              " 69,\n",
              " 26,\n",
              " 40,\n",
              " 73,\n",
              " 45,\n",
              " 13,\n",
              " 13,\n",
              " 13,\n",
              " 81,\n",
              " 69,\n",
              " 40,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 63,\n",
              " 19,\n",
              " 33,\n",
              " 13,\n",
              " 33,\n",
              " 92,\n",
              " 13,\n",
              " 33,\n",
              " 92,\n",
              " 33,\n",
              " 99,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 43,\n",
              " 78,\n",
              " 19,\n",
              " 70,\n",
              " 13,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 95,\n",
              " 44,\n",
              " 5,\n",
              " 33,\n",
              " 33,\n",
              " 40,\n",
              " 33,\n",
              " 44,\n",
              " 45,\n",
              " 33,\n",
              " 52,\n",
              " 33,\n",
              " 60,\n",
              " 44,\n",
              " 76,\n",
              " 33,\n",
              " 86,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 81,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 43,\n",
              " 33,\n",
              " 33,\n",
              " 59,\n",
              " 19,\n",
              " 82,\n",
              " 88,\n",
              " 33,\n",
              " 33,\n",
              " 92,\n",
              " 8,\n",
              " 33,\n",
              " 13,\n",
              " 82,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 33,\n",
              " 70,\n",
              " 33,\n",
              " 33,\n",
              " 44,\n",
              " 91,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 61,\n",
              " 33,\n",
              " 33,\n",
              " 78,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 68,\n",
              " 33,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 92,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 40,\n",
              " 76,\n",
              " 88,\n",
              " 33,\n",
              " 23,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 8,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 65,\n",
              " 33,\n",
              " 33,\n",
              " 8,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 44,\n",
              " 13,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 40,\n",
              " 13,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 92,\n",
              " 33,\n",
              " 59,\n",
              " 40,\n",
              " 33,\n",
              " 33,\n",
              " 70,\n",
              " 33,\n",
              " 33,\n",
              " 82,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 13,\n",
              " 44,\n",
              " 33,\n",
              " 16,\n",
              " 45,\n",
              " 33,\n",
              " 40,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 44,\n",
              " 92,\n",
              " 78,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 44,\n",
              " 3,\n",
              " 19,\n",
              " 60,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 57,\n",
              " 33,\n",
              " 44,\n",
              " 33,\n",
              " 33,\n",
              " 40,\n",
              " 13,\n",
              " 92,\n",
              " 33,\n",
              " 33,\n",
              " 88,\n",
              " 68,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 78,\n",
              " 33,\n",
              " 89,\n",
              " 44,\n",
              " 68,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 40,\n",
              " 33,\n",
              " 13,\n",
              " 33,\n",
              " 67,\n",
              " 44,\n",
              " 91,\n",
              " 33,\n",
              " 40,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 44,\n",
              " 99,\n",
              " 33,\n",
              " 5,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 33,\n",
              " 40,\n",
              " 33,\n",
              " 33,\n",
              " 49,\n",
              " 92,\n",
              " ...]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valores_kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlhtqNVRpiUA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Crea una lista que contendrá las filas del archivo CSV\n",
        "csv_data = []\n",
        "\n",
        "# Itera a través de las rutas de las imágenes y los valores predecidos\n",
        "for image_path, predicted_value in zip(test_all_paths, valores_kaggle):\n",
        "    predicted_value_str = str(predicted_value)  # Convierte el valor entero a cadena\n",
        "    food_category_key = findOuterKey(hierarchy_dict, dish_dict[predicted_value_str])\n",
        "    # Encuentra la clave correspondiente en el diccionario \"food_categories_dict\"\n",
        "    for key, value in food_categories_dict.items():\n",
        "        if food_category_key == value:\n",
        "            food_category_key = key\n",
        "\n",
        "    # Agrega una fila al archivo CSV con la ruta de la imagen y los valores separados por espacio\n",
        "    csv_data.append([image_path, f\"{food_category_key} {predicted_value_str}\"])\n",
        "\n",
        "# Ruta completa del archivo CSV en la carpeta especificada\n",
        "csv_filename = \"/content/drive/MyDrive/kaggle_tarea2/not_submission.csv\"\n",
        "\n",
        "# Escribe los datos en el archivo CSV\n",
        "with open(csv_filename, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    # Escribe los datos\n",
        "    csv_writer.writerows(csv_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNLBWKmC1CKU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "YJX05EPF0jfa",
        "outputId": "1f7db79d-5ba8-4d0a-d8f9-ef7a0829eba9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted class is: 26\n",
            "Dish: falafel\n",
            "Dish_real: breakfast_burrito\n"
          ]
        }
      ],
      "source": [
        "# Assuming x_val is your 4D image array\n",
        "pred_id = 5\n",
        "image_to_plot = test_x[pred_id]  # Select the first image from the 4D array\n",
        "\n",
        "# Rescale the pixel values to the [0, 1] range\n",
        "image_to_plot = image_to_plot / 255.0  # If the values are in [0, 255]\n",
        "\n",
        "plt.imshow(image_to_plot)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Assuming 'predictions[0]' is your array\n",
        "class_index = np.argmax(predictions_kaggle[pred_id])\n",
        "\n",
        "# 'class_index' now contains the index of the class with the highest score\n",
        "print(f\"The predicted class is: {class_index}\")\n",
        "print(f\"Dish:\",dish_dict[str(class_index)])\n",
        "print(f\"Dish_real:\",dish_dict[str(test_y[pred_id][0])])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}